{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827106c0-c077-4004-b535-0670b39cb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import cv2\n",
    "from PIL import Image as im\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import collections\n",
    "from typing import DefaultDict, Tuple, List, Dict\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append('early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a25006-1e3b-4104-af7a-1b8c4f0c2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve unique ID used to name a model when saving files related to it.\n",
    "# The current integer is the previously trained model. Training will increment the value.\n",
    "COUNTER_FILENAME = os.path.expanduser(\"model_counter.txt\")\n",
    "global MODEL_ID\n",
    "\n",
    "\n",
    "def update_model_id():\n",
    "    global MODEL_ID\n",
    "    with open(COUNTER_FILENAME, \"w\") as f:\n",
    "        count = int(MODEL_ID)\n",
    "        count += 1\n",
    "        count = str(count)\n",
    "        f.write(count)\n",
    "        MODEL_ID = count\n",
    "\n",
    "        \n",
    "def retrieve_model_id():\n",
    "    global MODEL_ID\n",
    "    try:\n",
    "        with open(COUNTER_FILENAME, 'r') as f:\n",
    "            count = f.read()\n",
    "            MODEL_ID = count\n",
    "    except FileNotFoundError:\n",
    "        print('New counter file.')\n",
    "        with open(COUNTER_FILENAME, 'w') as f:\n",
    "            count = '0'\n",
    "            f.write(count)\n",
    "            MODEL_ID = count\n",
    "\n",
    "            \n",
    "retrieve_model_id()\n",
    "\n",
    "# Adjust printing view dimensions\n",
    "np.set_printoptions(threshold=sys.maxsize, linewidth=300)\n",
    "torch.set_printoptions(threshold=sys.maxsize, linewidth=300, profile='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4234e113-ccb7-4dd2-a1e6-ea503eaa0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_shape = kwargs[\"input_shape\"]\n",
    "        # number of hidden units in first hidden layer\n",
    "        self.n_units = kwargs[\"n_units\"]\n",
    "        # number of hidden units in latent space\n",
    "        self.latent_units = kwargs[\"latent_units\"]\n",
    "        \n",
    "        self.encoder = nn.Sequentual(\n",
    "                            # Initial tensor is batch_sizex1x30x30\n",
    "                            nn.Conv2d(\n",
    "                                in_channels=1, \n",
    "                                out_channels=16,\n",
    "                                kernel_size=3, \n",
    "                                stride=2, \n",
    "                                padding=1),\n",
    "                            nn.BatchNorm2d(16),\n",
    "                            nn.ReLU(),\n",
    "                            # tensor is batch_sizex16x15x15 since:\n",
    "                            #   ((30 + (2 * 1) - (1 * (3 - 1)) - 1) / 2) + 1\n",
    "                            # = ((30 + 2 - 2 - 1) / 2) + 1\n",
    "                            # = (29 / 2) + 1 = 14 + 1 = 15\n",
    "                            nn.Conv2d(\n",
    "                                in_channels=16, \n",
    "                                out_channels=32,\n",
    "                                kernel_size=3, \n",
    "                                stride=2, \n",
    "                                padding=1),\n",
    "                            nn.BatchNorm2d(32),\n",
    "                            nn.ReLU())\n",
    "                            # tensor is batch_sizex32x8x8 since:\n",
    "                            # ((15 + (2 * 1) - (1 * (3 - 1)) - 1) / 2) + 1\n",
    "                            # = ((15 + 2 - 2 - 1) / 2) + 1\n",
    "                            # = (14 / 2) + 1 = 8\n",
    "        \n",
    "        # 32 * 8 * 8 = 2048\n",
    "        self.mean = nn.Linear(2048, 4)\n",
    "        self.log_var = nn.Linear(2048, 4)\n",
    "        \n",
    "        self.decoder_input = nn.Linear(4, 256)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(\n",
    "                                hidden_dims[i],\n",
    "                                hidden_dims[i + 1],\n",
    "                                kernel_size=3,\n",
    "                                stride = 2,\n",
    "                                padding=1,\n",
    "                                output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                                nn.ConvTranspose2d(\n",
    "                                    hidden_dims[-1],\n",
    "                                    hidden_dims[-1],\n",
    "                                    kernel_size=3,\n",
    "                                    stride=2,\n",
    "                                    padding=1,\n",
    "                                    output_padding=1),\n",
    "                                nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Conv2d(\n",
    "                                    hidden_dims[-1], \n",
    "                                    out_channels=3,\n",
    "                                    kernel_size=3, \n",
    "                                    padding=1),\n",
    "                                nn.Sigmoid())\n",
    "    def forward(self, X):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e9c12b-f197-4ec0-abcd-da29d0df1756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# 10,000 samples, 30x30 matrices\n",
    "data_count = 10000\n",
    "data = np.ndarray(shape=(data_count,30,30))\n",
    "n_features = data.shape[1] * data.shape[2]\n",
    "\n",
    "\n",
    "for i in range(data_count):\n",
    "    path = f'data/jet_matrices/sample{i+1}.dat'\n",
    "    sample = np.loadtxt(path, unpack = False)\n",
    "    data[i] = sample\n",
    "\n",
    "print(\"Done loading data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82af90bd-ba53-4da1-9d54-39c9e872a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading parameters.\n"
     ]
    }
   ],
   "source": [
    "# Load parameters corresponding to the 4 variables input into \n",
    "# the Helmholtz Resonator function, where output is each sample in dataset.\n",
    "params = np.ndarray(shape=(data_count,4))\n",
    "\n",
    "path = r'data/param_lhs.dat'\n",
    "with open(path) as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if i >= params.shape[0]:\n",
    "            break\n",
    "        param = np.fromstring(line, dtype=float, sep=',')\n",
    "        params[i] = param\n",
    "\n",
    "print(\"Done loading parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf92cf4-9a63-42eb-82e3-6f834f192e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Convert from numpy array to Pytorch tensor\n",
    "X = torch.from_numpy(data)\n",
    "# Convert all scalars to floats\n",
    "X = X.float()\n",
    "print(X.shape)\n",
    "\n",
    "X_with_params = []\n",
    "for i in range(data_count):\n",
    "    pair = [X[i], params[i], i]\n",
    "    X_with_params.append(pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigan] *",
   "language": "python",
   "name": "conda-env-bigan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
