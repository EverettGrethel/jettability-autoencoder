{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827106c0-c077-4004-b535-0670b39cb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as f\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import cv2\n",
    "from PIL import Image as im\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import collections\n",
    "from typing import DefaultDict, Tuple, List, Dict\n",
    "from functools import partial\n",
    "\n",
    "sys.path.append('early-stopping-pytorch')\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a25006-1e3b-4104-af7a-1b8c4f0c2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve unique ID used to name a model when saving files related to it.\n",
    "# The current integer is the previously trained model. Training will increment the value.\n",
    "COUNTER_FILENAME = os.path.expanduser(\"model_counter.txt\")\n",
    "global MODEL_ID\n",
    "\n",
    "\n",
    "def update_model_id():\n",
    "    global MODEL_ID\n",
    "    with open(COUNTER_FILENAME, \"w\") as f:\n",
    "        count = int(MODEL_ID)\n",
    "        count += 1\n",
    "        count = str(count)\n",
    "        f.write(count)\n",
    "        MODEL_ID = count\n",
    "\n",
    "        \n",
    "def retrieve_model_id():\n",
    "    global MODEL_ID\n",
    "    try:\n",
    "        with open(COUNTER_FILENAME, 'r') as f:\n",
    "            count = f.read()\n",
    "            MODEL_ID = count\n",
    "    except FileNotFoundError:\n",
    "        print('New counter file.')\n",
    "        with open(COUNTER_FILENAME, 'w') as f:\n",
    "            count = '0'\n",
    "            f.write(count)\n",
    "            MODEL_ID = count\n",
    "\n",
    "            \n",
    "retrieve_model_id()\n",
    "\n",
    "# Adjust printing view dimensions\n",
    "np.set_printoptions(threshold=sys.maxsize, linewidth=300)\n",
    "torch.set_printoptions(threshold=sys.maxsize, linewidth=300, profile='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4234e113-ccb7-4dd2-a1e6-ea503eaa0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequentual(\n",
    "                            # Initial tensor is batch_sizex1x30x30\n",
    "                            nn.Conv2d(\n",
    "                                in_channels=1, \n",
    "                                out_channels=32,\n",
    "                                kernel_size=3, \n",
    "                                stride=2, \n",
    "                                padding=1),\n",
    "                            nn.BatchNorm2d(32),\n",
    "                            nn.ReLU(),\n",
    "                            # tensor is batch_sizex32x15x15 since:\n",
    "                            #   ((30 + (2 * 1) - (1 * (3 - 1)) - 1) / 2) + 1\n",
    "                            # = ((30 + 2 - 2 - 1) / 2) + 1\n",
    "                            # = (29 / 2) + 1 = 14 + 1 = 15\n",
    "                            nn.Conv2d(\n",
    "                                in_channels=32, \n",
    "                                out_channels=64,\n",
    "                                kernel_size=3, \n",
    "                                stride=2, \n",
    "                                padding=1),\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            nn.ReLU(),\n",
    "                            # tensor is batch_sizex64x8x8 since:\n",
    "                            # ((15 + (2 * 1) - (1 * (3 - 1)) - 1) / 2) + 1\n",
    "                            # = ((15 + 2 - 2 - 1) / 2) + 1\n",
    "                            # = (14 / 2) + 1 = 8\n",
    "                            nn.Conv2d(\n",
    "                                in_channels=64, \n",
    "                                out_channels=900,\n",
    "                                kernel_size=3, \n",
    "                                stride=2, \n",
    "                                padding=1),\n",
    "                            nn.BatchNorm2d(900),\n",
    "                            nn.ReLU())\n",
    "                            # tensor is batch_sizex900x4x4 since:\n",
    "                            # ((8 + (2 * 1) - (1 * (3 - 1)) - 1) / 2) + 1\n",
    "                            # = ((8 + 2 - 2 - 1) / 2) + 1\n",
    "                            # = (7 / 2) + 1 = 4\n",
    "        \n",
    "        # 900 * 4 * 4 = 14400\n",
    "        self.mean = nn.Linear(14400, 4)\n",
    "        self.log_var = nn.Linear(14400, 4)\n",
    "        \n",
    "        self.decoder_input = nn.Linear(4, 14400)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(\n",
    "                                in_channels=900,\n",
    "                                out_channels=64,\n",
    "                                kernel_size=3,\n",
    "                                stride = 2,\n",
    "                                padding=1,\n",
    "                                output_padding=1),\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            nn.ReLU(),\n",
    "                            nn.ConvTranspose2d(\n",
    "                                in_channels=64,\n",
    "                                out_channels=32,\n",
    "                                kernel_size=3,\n",
    "                                stride = 2,\n",
    "                                padding=1,\n",
    "                                output_padding=1),\n",
    "                            nn.BatchNorm2d(32),\n",
    "                            nn.ReLU())\n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                                nn.ConvTranspose2d(\n",
    "                                    in_channels=32,\n",
    "                                    out_channels=32,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=2,\n",
    "                                    padding=1,\n",
    "                                    output_padding=1),\n",
    "                                nn.BatchNorm2d(16),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Conv2d(\n",
    "                                    in_channels=32, \n",
    "                                    out_channels=1,\n",
    "                                    kernel_size=3, \n",
    "                                    padding=1),\n",
    "                                nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "    def encode(self, data):\n",
    "        result = self.encoder(data)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        mean = self.mean(result)\n",
    "        log_var = self.log_var(result)\n",
    "\n",
    "        return [mean, log_var]\n",
    "\n",
    "    \n",
    "    def decode(self, z):\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 900, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    \n",
    "    def forward(self, data, **kwargs):\n",
    "        mean, log_var = self.encode(data)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        return [self.decode(z), data, mean, log_var]\n",
    "    \n",
    "    \n",
    "    def loss_function(self, *args, **kwargs):\n",
    "        recons = args[0]\n",
    "        data = args[1]\n",
    "        mean = args[2]\n",
    "        log_var = args[3]\n",
    "\n",
    "        kld_weight = kwargs['beta'] # Account for the minibatch samples from the dataset\n",
    "        recons_loss = nn.BCEloss(recons, data)\n",
    "\n",
    "        kld = torch.mean(-0.5 * torch.sum(1 + log_var - mean ** 2 - log_var.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        loss = recons_loss + kld_weight * kld\n",
    "        return {'loss': loss, 'Reconstruction_Loss':recons_loss.detach(), 'KLD':-kld_loss.detach()}\n",
    "\n",
    "    \n",
    "    def sample(self, num_samples, current_device, **kwargs):\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    \n",
    "    def generate(self, x, **kwargs):\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97e9c12b-f197-4ec0-abcd-da29d0df1756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading data.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "# 10,000 samples, 30x30 matrices\n",
    "data_count = 10000\n",
    "data = np.ndarray(shape=(data_count,30,30))\n",
    "n_features = data.shape[1] * data.shape[2]\n",
    "\n",
    "\n",
    "for i in range(data_count):\n",
    "    path = f'data/jet_matrices/sample{i+1}.dat'\n",
    "    sample = np.loadtxt(path, unpack = False)\n",
    "    data[i] = sample\n",
    "\n",
    "print(\"Done loading data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82af90bd-ba53-4da1-9d54-39c9e872a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading parameters.\n"
     ]
    }
   ],
   "source": [
    "# Load parameters corresponding to the 4 variables input into \n",
    "# the Helmholtz Resonator function, where output is each sample in dataset.\n",
    "params = np.ndarray(shape=(data_count,4))\n",
    "\n",
    "path = r'data/param_lhs.dat'\n",
    "with open(path) as f:\n",
    "    lines = f.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if i >= params.shape[0]:\n",
    "            break\n",
    "        param = np.fromstring(line, dtype=float, sep=',')\n",
    "        params[i] = param\n",
    "\n",
    "print(\"Done loading parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faf92cf4-9a63-42eb-82e3-6f834f192e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "# Convert from numpy array to Pytorch tensor\n",
    "X = torch.from_numpy(data)\n",
    "# Convert all scalars to floats\n",
    "X = X.float()\n",
    "print(X.shape)\n",
    "\n",
    "X_with_params = []\n",
    "for i in range(data_count):\n",
    "    pair = [X[i], params[i], i]\n",
    "    X_with_params.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e44e5965-edce-4160-9c41-d139b5f7336b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000\n",
      "3000\n",
      "1500\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 32\n",
    "# 70/15/15 split\n",
    "train_size = int(0.7 * len(X))\n",
    "val_test_size = len(X) - train_size\n",
    "test_size = val_test_size // 2\n",
    "    \n",
    "val_size = val_test_size - test_size\n",
    "\n",
    "print(train_size)\n",
    "print(val_test_size)\n",
    "print(test_size)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ecd5236-d54d-4c72-a004-395918692764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Initate data loaders\n",
    "\n",
    "train, val = torch.utils.data.random_split(X_with_params, [train_size, val_test_size], generator=torch.Generator().manual_seed(5))\n",
    "val, test = torch.utils.data.random_split(val, [val_size, test_size], generator=torch.Generator().manual_seed(5))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# Same as test_loader but with stochastic batch size\n",
    "test_loader_stoch = torch.utils.data.DataLoader(\n",
    "    test, batch_size=1, shuffle=False, num_workers=0, pin_memory=True\n",
    ")\n",
    "\n",
    "# Use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98181290-8aa1-4a31-a498-41bb93387351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(model, epochs, lr, is_early_stopping=False, patience=None, beta=None, rho=None):\n",
    "    # Define Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # Binary Cross Entropy Loss\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Reset model state\n",
    "    def weights_init(m):\n",
    "        if type(m) == nn.Sequential:\n",
    "            children = dict(m.named_children())\n",
    "            # Use Kaiming if ReLU, Xavier if Sigmoid.\n",
    "            if type(children['1']) == nn.ReLU:\n",
    "                nn.init.kaiming_uniform_(children['0'].weight.data, nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.xavier_uniform_(children['0'].weight.data)\n",
    "            \n",
    "    model.apply(weights_init)\n",
    "    \n",
    "    # Toggle Early Stopping (if using).\n",
    "    if is_early_stopping:\n",
    "        early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        print(\"Using Early Stopping\")\n",
    "\n",
    "    print(\"Training...\")\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #############################    \n",
    "        #          TRAINING         #\n",
    "        #############################\n",
    "        \n",
    "        loss = 0\n",
    "        # Prepare model for training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for i, batch in enumerate(train_loader, 0):\n",
    "            # remove params, keep data\n",
    "            batch = batch[0]\n",
    "            # reshape mini-batch data from [batch_size, 30, 30] to [batch_size, 900]\n",
    "            # load it to the active device\n",
    "            batch = batch.view(-1, n_features).to(device)\n",
    "\n",
    "            # reset the gradients back to zero\n",
    "            # PyTorch accumulates gradients on subsequent backward passes\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # compute reconstructions\n",
    "            # also retrieve bottleneck weights for computing sparsity penalty\n",
    "            decoded = model(batch)\n",
    "\n",
    "            # Exception handler for when BCE loss has values outside range [0.0, 1.0]\n",
    "            try:\n",
    "                # Compute training reconstruction loss\n",
    "                train_loss = criterion(decoded, batch)\n",
    "            except RuntimeError:\n",
    "                print('Runtime Error during loss calculation. BCE loss has values outside range [0.0, 1.0]')\n",
    "                for k, sample in enumerate(decoded):\n",
    "                    print(k)\n",
    "                    print(sample)\n",
    "                    \n",
    "            train_loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb86562-4194-4dc4-8864-731245ec513f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     11\u001b[0m basic_model \u001b[38;5;241m=\u001b[39m VAE(input_shape\u001b[38;5;241m=\u001b[39mn_features,\n\u001b[1;32m---> 12\u001b[0m                     n_units\u001b[38;5;241m=\u001b[39m\u001b[43mn_units\u001b[49m,\n\u001b[0;32m     13\u001b[0m                     latent_units\u001b[38;5;241m=\u001b[39mlatent_units\n\u001b[0;32m     14\u001b[0m                    )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_units' is not defined"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 200\n",
    "\n",
    "# Boolean for whether to use Early Stopping\n",
    "is_early_stopping = True\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 10\n",
    "\n",
    "torch.manual_seed(5)\n",
    "\n",
    "basic_model = VAE(input_shape=n_features,\n",
    "                    n_units=n_units,\n",
    "                    latent_units=latent_units\n",
    "                   ).to(device)\n",
    "\n",
    "# vae_trained = train_validate(model=basic_model,\n",
    "#                             epochs=epochs,\n",
    "#                             lr=lr,\n",
    "#                             is_early_stopping=is_early_stopping, \n",
    "#                             is_pca=is_pca,\n",
    "#                             patience=patience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bigan] *",
   "language": "python",
   "name": "conda-env-bigan-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
